{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e6b228",
   "metadata": {},
   "source": [
    "### Задание №1.\n",
    "Обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d9cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f6a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.get_dummies(X, prefix=self.key)[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf35108",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "for cat_col in cat_cols:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=base_col))\n",
    "            ])\n",
    "    base_transformers.append((base_col, base_transformer))\n",
    "\n",
    "feats = FeatureUnion(continuos_transformers + cat_transformers + base_transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f592420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_case2.csv', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4ffa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='cardio'), \n",
    "                                                    df['cardio'], random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45986ae7",
   "metadata": {},
   "source": [
    "__Логистическая регрессия:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5ded48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.78840 +- 0.00591\n"
     ]
    }
   ],
   "source": [
    "lr = Pipeline([('features', feats),\n",
    "               ('classifier', LogisticRegression(random_state=23))])\n",
    "\n",
    "cv_scores = cross_val_score(lr, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print(f'CV score is {cv_score:.5f} +- {cv_score_std:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809cec94",
   "metadata": {},
   "source": [
    "__Случайный лес:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980ff0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.80231 +- 0.00460\n"
     ]
    }
   ],
   "source": [
    "rfc = Pipeline([('features', feats),\n",
    "                ('classifier', RandomForestClassifier(n_estimators=80,\n",
    "                                                      max_depth=9,\n",
    "                                                      random_state=23))])\n",
    "\n",
    "cv_scores = cross_val_score(rfc, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print(f'CV score is {cv_score:.5f} +- {cv_score_std:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb4adb",
   "metadata": {},
   "source": [
    "__Градиентный бустинг:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f71e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.80409 +- 0.00490\n"
     ]
    }
   ],
   "source": [
    "gbc = Pipeline([('features', feats),\n",
    "                ('classifier', GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                                          n_estimators=110,\n",
    "                                                          max_depth=4,\n",
    "                                                          random_state=23))])\n",
    "\n",
    "cv_scores = cross_val_score(gbc, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print(f'CV score is {cv_score:.5f} +- {cv_score_std:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede45ee",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb6e83",
   "metadata": {},
   "source": [
    "### Задание №2.\n",
    "Вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4059c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Optimal threshold</th>\n",
       "      <th>ROC AUC score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.735101</td>\n",
       "      <td>0.657171</td>\n",
       "      <td>0.834001</td>\n",
       "      <td>0.391695</td>\n",
       "      <td>0.783973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.740866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>0.828166</td>\n",
       "      <td>0.367101</td>\n",
       "      <td>0.796581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.741637</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>0.834458</td>\n",
       "      <td>0.346801</td>\n",
       "      <td>0.799145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F score  Precision    Recall  Optimal threshold  \\\n",
       "Classifier                                                              \n",
       "Logistic Regression  0.735101   0.657171  0.834001           0.391695   \n",
       "Random Forest        0.740866   0.670216  0.828166           0.367101   \n",
       "Gradient Boosting    0.741637   0.667399  0.834458           0.346801   \n",
       "\n",
       "                     ROC AUC score  \n",
       "Classifier                          \n",
       "Logistic Regression       0.783973  \n",
       "Random Forest             0.796581  \n",
       "Gradient Boosting         0.799145  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_metric_table = []\n",
    "models_pred_proba_values = []\n",
    "\n",
    "for model in ['lr', 'rfc', 'gbc']:\n",
    "    eval(f'{model}.fit(X_train, y_train)')\n",
    "    preds = eval(f'{model}.predict_proba(X_test)[:, 1]')\n",
    "    models_pred_proba_values.append(preds)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "    precision[(precision == 0) & (recall == 0)] = np.e-10\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    "    pivot_metric_table.append((fscore[ix], precision[ix], recall[ix], thresholds[ix], roc_auc_score(y_test, preds)))\n",
    "\n",
    "pivot_metric_table = pd.DataFrame(pivot_metric_table)\n",
    "pivot_metric_table.columns = ['F score', 'Precision', 'Recall', 'Optimal threshold', 'ROC AUC score']\n",
    "pivot_metric_table['Classifier'] = ['Logistic Regression', 'Random Forest', 'Gradient Boosting']\n",
    "pivot_metric_table.set_index('Classifier', inplace=True)\n",
    "pivot_metric_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77022573",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f370e",
   "metadata": {},
   "source": [
    "### Задание №3.\n",
    "Вывести сравнение полученных моделей по метрикам бизнеса по показателям с урока:\n",
    "   - стоимость лечения 15000р, если сделали тест и начали лечить вовремя;\n",
    "   - стоимость лечения 20000р, если упустили и начали лечить когда уже проявились все симптомы;\n",
    "   - стоимость теста 1400р."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3f4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_business_costs(y_test, y_preds, treshold=0.5,\n",
    "                       test_cost=1400, early_treatment_cost=15000, late_treatment_cost=20000):\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_preds > treshold)\n",
    "    TN = cnf_matrix[0][0]\n",
    "    FN = cnf_matrix[1][0]\n",
    "    TP = cnf_matrix[1][1]\n",
    "    FP = cnf_matrix[0][1]\n",
    "    \n",
    "    late_costs = (FN + TP) * late_treatment_cost\n",
    "    test_all_costs = np.sum(cnf_matrix) * test_cost + (FN + TP) * early_treatment_cost\n",
    "    ml_costs = (FP + TP) * test_cost + FN * late_treatment_cost + TP * early_treatment_cost\n",
    "    \n",
    "    return late_costs, test_all_costs, ml_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e954aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_lr = get_business_costs(y_test, models_pred_proba_values[0], pivot_metric_table.iloc[0, 3])\n",
    "costs_rfc = get_business_costs(y_test, models_pred_proba_values[1], pivot_metric_table.iloc[1, 3])\n",
    "costs_gbc = get_business_costs(y_test, models_pred_proba_values[2], pivot_metric_table.iloc[2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e22f5",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1dcf2",
   "metadata": {},
   "source": [
    "### Задание №4.\n",
    "Сделать выводы о том, какая модель справилась с задачей лучше других."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0048ce66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прибыль от применения \"Логистической регрессии\" относительно вариантов:\n",
      "\"без тестов\": 20916200 р.\n",
      "\"тесты всем\": 1711200 р.\n",
      "\n",
      "Прибыль от применения \"Случайного леса\" относительно вариантов:\n",
      "\"без тестов\": 21070000 р.\n",
      "\"тесты всем\": 1865000 р.\n",
      "\n",
      "Прибыль от применения \"Градиентного бустинга\" относительно вариантов:\n",
      "\"без тестов\": 21165800 р.\n",
      "\"тесты всем\": 1960800 р.\n"
     ]
    }
   ],
   "source": [
    "print(f'Прибыль от применения \"Логистической регрессии\" относительно вариантов:\\n'\n",
    "      f'\"без тестов\": {costs_lr[0] - costs_lr[2]} р.\\n'\n",
    "      f'\"тесты всем\": {costs_lr[1] - costs_lr[2]} р.\\n')\n",
    "print(f'Прибыль от применения \"Случайного леса\" относительно вариантов:\\n'\n",
    "      f'\"без тестов\": {costs_rfc[0] - costs_rfc[2]} р.\\n'\n",
    "      f'\"тесты всем\": {costs_rfc[1] - costs_rfc[2]} р.\\n')\n",
    "print(f'Прибыль от применения \"Градиентного бустинга\" относительно вариантов:\\n'\n",
    "      f'\"без тестов\": {costs_gbc[0] - costs_gbc[2]} р.\\n'\n",
    "      f'\"тесты всем\": {costs_gbc[1] - costs_gbc[2]} р.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ff06b",
   "metadata": {},
   "source": [
    "Как видим из прибыли: лучше всего показала себя модель классификатора методом градиентного бустинга. Отрыв по прибыли от второй по качеству модели, случайного леса: 95800 рублей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ce700",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e423e",
   "metadata": {},
   "source": [
    "### Задание №5.\n",
    "Найти порог классификации по деньгам для лучшей модели:\n",
    "   - Стоимость лечения 15000р, если сделали тест и начали лечить вовремя;\n",
    "   - Стоимость лечения 20000р, если упустили и начали лечить когда уже проявились все симптомы;\n",
    "   - Стоимость теста 1400р."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc6c952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_business_th(y_test, y_preds, n_thresholds=20,\n",
    "                            test_cost=1400, early_treatment_cost=15000, late_treatment_cost=20000):\n",
    "    best_profit = 0\n",
    "    opt_th = None\n",
    "    best_costs = None\n",
    "    \n",
    "    for th in np.linspace(0, 1, n_thresholds + 1):\n",
    "        \n",
    "        cnf_matrix = confusion_matrix(y_test, y_preds > th)\n",
    "        TN = cnf_matrix[0][0]\n",
    "        FN = cnf_matrix[1][0]\n",
    "        TP = cnf_matrix[1][1]\n",
    "        FP = cnf_matrix[0][1]\n",
    "    \n",
    "        late_costs = (FN + TP) * late_treatment_cost\n",
    "        test_all_costs = np.sum(cnf_matrix) * test_cost + (FN + TP) * early_treatment_cost\n",
    "        ml_costs = (FP + TP) * test_cost + FN * late_treatment_cost + TP * early_treatment_cost\n",
    "        \n",
    "        if (test_all_costs - ml_costs) > best_profit:\n",
    "            opt_th = th\n",
    "            best_profit = test_all_costs - ml_costs\n",
    "            best_costs = late_costs, test_all_costs, ml_costs\n",
    "    \n",
    "    return opt_th, best_profit, best_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd1efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_th = get_optimal_business_th(y_test, models_pred_proba_values[2], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e6dd41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная прибыль от ML относительно варианта тестирования всех при пороге 0.26: 2221400 рублей.\n",
      "Аналогичная прибыль от ML при пороге 0.35 (лучшем согласно f_score): 1960800 рублей.\n"
     ]
    }
   ],
   "source": [
    "print(f'Максимальная прибыль от ML относительно варианта тестирования всех при пороге {opt_th[0]}: {opt_th[1]} рублей.')\n",
    "print(f'Аналогичная прибыль от ML при пороге {pivot_metric_table.iloc[2, 3]:.2f} (лучшем согласно f_score): {costs_gbc[1] - costs_gbc[2]} рублей.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
